// Copyright (C) 2020, RTE (http://www.rte-france.com)

Seapath Yocto BSP Platform Developer Guide
==========================================
:toc:
:icons:
:iconsdir: ./doc/icons/
:sectnumlevels: 1

The Yocto firmware generation has been tested on Ubuntu 18.04. You can either
use your host machine's tools, or use
https://github.com/savoirfairelinux/cqfd[cqfd] to build. More details are given
in the next sections of this document.

== Release Notes

=== Version 0.1 (March 6 2020)

* Generates a default Yocto image
* Supports UEFI legacy

=== Version 0.2 (March 16 2020)

* Use preempt RT Linux Kernel
* Supports UEFI
* Adds RT-tests

=== Version 0.3 (March 27 2020)

* Adds KVM/Qemu support
* Adds libvirt / virsh tools for VM management
* Adds RT tests on guest machines

=== Version 0.4 (April 10 2020)

* Adds Openvswtich / DPDK support
* Adds Docker and Kubernetes
* Adds VM deployment and testing tools

=== Version 0.5 (April 24 2020)

* Enhances boot time
* Adds Yocto ptests

=== Version 0.6 (April 25 2020)

* Fixes regression in libvirt

=== Version 0.7 (April 30 2020)

* Adds missing drivers for intel I210
* Adds PMD drivers for dpdk
* Adds pciutils for dpdk

=== Version 0.8 (May 18 2020)

* Adds igb_uio and virtio support for Openvswitch / dpdk

=== Version 0.9 (May 27 2020)

* Add guest images in qcow2 format
* Compressed generated host images
* Add a partition data mount in /var in all images
* Update flash description

=== Version 0.10 (Jul 3 2020)

* Adds a High Availability VM solution based on Pacemaker
* Adds a Distributed Storage solution based on Ceph
* Adds a test tool to check data synchronization

=== Version 0.11 (Aug 23 2020)

* Adds support for interfacing with an Active Directory using SSSD/Realmd
* Adds support for user authentication from a RADIUS server

=== Version 0.12 (Sep 28 2020)

 * Adds deployment scripts to perform a configuration similar to the High
   Availability test setup
 * Fixes upstream source download issues
 * Does not start unconfigured systemd services at startup
 * Add "test" and "debug" image variants with BIOS support
 * Generates "guest" images in Vmware disk format

:numbered:

== Environment setup

=== SSH keys

The firmware source code is fetched from several git repositories. Some
of them are public and require no credentials.

The part specific to Seapath is stored on the LF Energy github.

If you don't already have a set of SSH keys in the `~/.ssh` directory of your
build machine, you can create them by running:

  $ ssh-keygen -t rsa -C <your_email@youremail.com>

Then, connect to https://g1.sfl.team[gerrit] and authenticate using your
provided user and password.

In the top right corner:

* Click on "Settings"
* Go to the "SSH Public Keys" section.
* Add the contents of your public SSH key (with the .pub extension). The default
  SSH public key path should be `~/.ssh/id_rsa.pub`.

=== Git defaults

If you want to fetch the source code from SFL's Git server, add these default
`User` and `Port` directives to your `~/.ssh/config`:

```
Host g1.sfl.team
    Port 29419
    User your_username
```

NOTE: Specify the SFL username that was provided to you.

== Fetching the source using Git

We are using `repo` to synchronize the source code using a manifest (an XML
file) which describes all git repositories required to build a firmware. The
manifest file is hosted in a git repository named `repo-manifest`.

First initialize `repo`:

  $ cd my_project_dir/
  $ repo init -u <manifest_repo_url>
  $ repo sync

For instance, for Seapath yocto-bsp project:

  $ cd my_project_dir/
  $ repo init -u ssh://g1.sfl.team:29419/rte/votp/repo-manifest
  $ repo sync

Once the sync is completed, you should see a git repository named `yocto-bsp`,
within which all the Yocto layers were fetched under the `yocto-bsp/sources`
sub-directory.

  $ cd yocto-bsp/

NOTE: The initial build process takes approximately 4 to 5 hours on a current
developer machine and will produce approximately 50GB of data.

== Building a firmware using cqfd

`cqfd` is a quick and convenient way to run commands in the current directory,
but within a pre-defined Docker container. Using `cqfd` allows you to avoid
installing anything else than Docker and `repo` on your development machine.

NOTE: We recommend using this method as it greatly simplifies the build
configuration management process.

=== Prerequisites

* Install repo and docker if it is not already done.

On Ubuntu, please run:

  $ sudo apt-get install repo docker.io

* Install cqfd:

```
$ git clone https://github.com/savoirfairelinux/cqfd.git
$ cd cqfd
$ sudo make install
```

The project page on https://github.com/savoirfairelinux/cqfd[Github] contains
detailed information on usage and installation.

* Make sure that docker does not require sudo

Please use the following commands to add your user account to the `docker`
group:

```
$ sudo groupadd docker
$ sudo usermod -aG docker $USER
```

Log out and log back in, so that your group membership can be re-evaluated.

=== Building the firmware

The first step with `cqfd` is to create the build container. For this, use the
`cqfd init` command:

  $ cd yocto-bsp/
  $ cqfd init

NOTE: The step above is only required once, as once the container image has been
created on your machine, it will become persistent. Further calls to `cqfd init`
will do nothing, unless the container definition (`.cqfd/docker/Dockerfile`) has
changed in the source tree.

You can then start the build using:

  $ cqfd run

== Building the firmware manually

This method relies on the manual installation of all the tools and dependencies
required on the host machine.

=== Prerequisites on Ubuntu

The following packages need to be installed:

  $ sudo apt-get update && apt-get install -y ca-certificates build-essential

  $ sudo apt-get install -y gawk wget git-core diffstat unzip texinfo gcc-multilib \
     build-essential chrpath socat cpio python python3 python3-pip python3-pexpect \
     xz-utils debianutils iputils-ping libsdl1.2-dev xterm repo

=== Building the firmware

The build is started by running the following command:

  $ ./build.sh -i seapath-image -m boardname

You can also pass custom BitBake commands using the `--` separator:

  $ ./build.sh -i seapath-image -m boardname -- bitbake -c clean package_name

Three Yocto images are available:

* seapath-image: production image to work with UEFI
* seapath-bios-image: production image to work with BIOS/UEFI legacy
* seapath-dbg-image: production image with debug tools
* seapath-test-image: production image with test tools
* seapath-guest-image: guest production image to work whith qemu
* seapath-guest-dbg-image: guest production image with debug tools
* seapath-guest-test-image: guest production image with test tools

== Building an SDK Installer

You can create an SDK matching your system's configuration using with the
following command:

  $ ./build.sh -i seapath -m boardname --sdk

NOTE: prefix this command with `cqfd run` if using cqfd.

When the bitbake command completes, the toolchain installer will be in
`tmp/deploy/sdk/` under your build directory.

== Flashing the firmware to an SD Card or USB key

On a Linux system, you can use the `dd` command. Firmware are compressed in gzip
format, it must be decompress with gzip first For instance, if the SD Card or
USB key device is /dev/sdx:

  $ sudo umount /dev/sdx*
  $ gzip -d -c build/tmp/deploy/image/boardname/seapath-image-boardname.wic.gz \
      | sudo dd of=/dev/sdx bs=16M conv=fsync

== Flashing the firmware to the disk


Copy the generated image in format wic.gz in a Linux live usb distribution.

Boot the usb key. You can flash the disk as an SD card or USB key.
To find the correct /dev/sdx matching your disk you can use the following
command:

  $ sudo lshw -class disk

== Tests

=== Cukinia tests

Here is the list of tests done so far.

.Tests
[width="100%",cols="20%,40%,40%",frame="topbot",options="header"]
|====================================================================================================================
|Name                           | Description                                 | Command
|00-cukinia-installation.conf   | Check that Cukinia is installed             | _cukinia /etc/cukinia/tests.d/00-cukinia-installation.conf_
|01-sw-versions.conf            | Check that Kernel version is at least
                                  4.19.106                                    | _cukinia /etc/cukinia/tests.d/01-sw_versions.conf_

|02-preempt-rt.conf             | Check that the running Kernel is preempt
                                  RT                                          | _cukinia /etc/cukinia/tests.d/02-preempt-rt.conf

|03-no-kernel-errors.conf       | Check that the running Kernel does not
                                  raise any warnings and errors               | _cukinia /etc/cukinia/tests.d/03-no-Kernel-errors.conf
|04-virtualization.conf         | Check virtulization minimal requirements    | _cukinia /etc/cukinia/tests.d/04-virtulization.conf
|05-container.conf              | Check that container daemon is running      | _cukinia /etc/cukinia/tests.d/05-container.conf
|06-ovs.conf                    | Check that ovs/dpdk runs correctly          | _cukinia /etc/cukinia/tests.d/06-ovs.conf
|07-systemd.conf                | Check that no systemd services have failed  | _cukinia /etc/cukinia/tests.d/07-systemd.conf
|====================================================================================================================

*Note:* All Cukinia tests can be executed in a row running:

  $ cukinia

=== Performance tests

The Yocto image _seapath-test-image_ incudes Real Time tests such as cyclictest.

On the target, call:

 $ cyclictest -l100000000 -m -Sp90 -i200 -h400 -q >output

*Note:* This test will run around 5 hours
Then generate the graphics:

 $ ./yocto-bsp/tools/gen_cyclic_test.sh -i output -n 28 -o seapath.png

*Note:* we reused OSADL http://www.osadl.org/Create-a-latency-plot-from-cyclictest-hi.bash-script-for-latency-plot.0.html[tools].

=== Virtualization tests

==== KVM unit tests

The Yocto image _seapath-test-image_ includes https://www.linux-kvm.org/page/KVM-unit-tests[kvm-unit-tests].

On the target, call:

 $ run_tests.sh

==== KVM/Qemu guest tests

All Seapath Yocto images include the ability to run guest Virtual Machines (VMs).

We used KVM and Qemu to run them. As we do not have any window manager on the host system,
VMs should be launched in console mode and their console output must be correctly set.

For testing purpose, we can run our Yocto image as a guest machine.
We do not use the _.wic_ image which includes the Linux Kernel and the rootfs because
we need to set the console output.
We use two distinct files to modify the Linux Kernel command line:

- _bzImage_: the Linux Kernel image
- _seapath-test-image-votp.ext4_: the Seapath rootfs

Then run:

 $ qemu-system-x86_64 -accel kvm -kernel bzImage -m 4096 -hda seapath-test-image-votp.ext4 -nographic -append 'root=/dev/sda console=ttyS0'

=== Yocto ptests

Ptest (package test) is a concept for building, installing and running the test suites
that are included in many upstream packages, and producing a consistent output format
for the results.

ptest-runner is included in _seapath_test_image_ and allows to run those tests.

For instance:

 $ ptest-runner openvswitch libvirt qemu rt-tests

The usage for the ptest-runner is as follows:

    $ Usage: ptest-runner [-d directory] [-l list] [-t timeout] [-h] [ptest1 ptest2 ...]

== About this documentation

This documentation uses the AsciiDoc documentation generator. It is a convenient
format that allows using plain-text formatted writing that can later be
converted to various output formats such as HTML and PDF.

In order to generate an HTML version of this documentation, use the following
command (the asciidoc package will need to be installed in your Linux
distribution):

  $ asciidoc README.adoc

This will result in a README.html file being generated in the current directory.

If you prefer a PDF version of the documentation instead, use the following
command (the dblatex package will need to be installed on your Linux
distribution):

  $ asciidoctor-pdf README.adoc
